<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VoiceBot</title>
</head>
<body>
    <h1>VoiceBot with Speech Recognition</h1>
    
    <button id="startRecording">Start Recording</button>
    <button id="stopRecording" disabled>Stop Recording</button>
    <audio id="audioPlayer" controls></audio>

    <script>
        let mediaRecorder;
        let audioChunks = [];
    
        document.getElementById("startRecording").addEventListener("click", async function () {
            audioChunks = [];
    
            console.log("navigator mediaDevices");
            console.log(navigator.mediaDevices);
            try {

                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream, { mimeType: "audio/webm" }); // Ensure WebM format
    
                mediaRecorder.ondataavailable = event => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };
    
                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
                    console.log("Recorded Audio Blob:", audioBlob);
                    sendAudioToBackend(audioBlob);
                };
    
                mediaRecorder.start();
                console.log("Recording started...");
                document.getElementById("startRecording").disabled = true;
                document.getElementById("stopRecording").disabled = false;
    
            } catch (error) {
                console.error("Error accessing microphone:", error);
            }
        });
    
        document.getElementById("stopRecording").addEventListener("click", function () {
            if (mediaRecorder && mediaRecorder.state !== "inactive") {
                mediaRecorder.stop();
                console.log("Recording stopped...");
                document.getElementById("startRecording").disabled = false;
                document.getElementById("stopRecording").disabled = true;
            }
        });
    
        async function sendAudioToBackend(audioBlob) {
            const formData = new FormData();
            formData.append("audio", audioBlob, "audio.webm"); // Ensure WebM format
    
            console.log("Sending audio to backend...");
            console.log("FormData Content:", formData.get("audio"));
    
            try {
                const response = await fetch("http://172.16.17.1:5000/process_audio", {
                    method: "POST",
                    body: formData,
                    headers: { "Accept": "application/json" },
                });
    
                const data = await response.json();
                console.log("API Response:", data);
    
                if (data.audio_url) {
                    console.log("Playing received audio...");
                    playAudio(data.audio_url);
                } else {
                    console.error("Error: No audio URL received.");
                }
            } catch (error) {
                console.error("Fetch error:", error);
            }
        }
    
        function playAudio(audioUrl) {
            fetch(audioUrl)
                .then(response => response.blob())
                .then(blob => {
                    const audioPlayer = document.getElementById("audioPlayer");
                    const objectURL = URL.createObjectURL(blob);
                    audioPlayer.src = objectURL;
                    audioPlayer.load();
                    
                    audioPlayer.play().catch(error => {
                        console.error("Autoplay failed:", error);
                    });
                })
                .catch(error => console.error("Error fetching audio:", error));
        }
    </script>
    
</body>
</html>
